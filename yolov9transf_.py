# YOLOv5 to YOLOv9 CONVERSION TRANSFER PROJECT
# -*- coding: utf-8 -*-
"""Yolov9transf.

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YNTlGfZSv32dVtSlz2LpVRSJBNGaJ7wn

# This work was fully supported by the U.S. National Science Foundation (EEC- 2133516).
"""

import os
HOME = os.getcwd()
print(HOME)

# Commented out IPython magic to ensure Python compatibility.
!pip install roboflow
!git clone https://github.com/WongKinYiu/yolov9.git  # clone YOLOv9 repo
# %cd yolov9
!pip install -r requirements.txt -q
!ls  # List files in the directory

!pip uninstall yolov9

#This is the test to see how one would look like for one

import albumentations as A
import cv2
import matplotlib.pyplot as plt


image = cv2.imread('/content/unzip_test/train/images/extract_first-recording_100_jpg.rf.d1fa8958e130ebb19dc9eb6003a23511.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Apply CLAHE
clahe = A.CLAHE(p=2)
transformed = clahe(image=image)['image']
plt.imshow(transformed)
plt.title('CLAHE')
plt.show()

# Apply HueSaturationValue
hsv = A.HueSaturationValue(p=2)
transformed = hsv(image=image)['image']
plt.imshow(transformed)
plt.title('HueSaturationValue')
plt.show()

# Apply the OneOf transformation
transform = A.OneOf([
    A.CLAHE(p=1),
    A.HueSaturationValue(p=1)
], p=0.9)

transformed = transform(image=image)['image']
plt.imshow(transformed)
plt.title('OneOf Transform')
plt.show()

transform = A.OneOf([
    A.CLAHE(p=1),
    A.HueSaturationValue(p=1)
], p=1)

transformed = transform(image=image)['image']
plt.imshow(transformed)
plt.title('OneOf Transform with p=1')
plt.show()

!pip install roboflow

import roboflow
roboflow.login()

"""This improts the version I've created from roboflow and put it in here with the my personal API key"""

import roboflow

roboflow.login()
rf = roboflow.Roboflow(api_key="Xy9TSDYjSvrRt3AWLG80")
project = rf.workspace().project("social-distancing-app-2.0")
dataset = project.version(2).download("yolov9")

!pip uninstall tensorflow

!pip install tensorflow==v2.16.1 #had to unistall this one because it can cause potential conflict

!pip uninstall tensorflow==v2.16.1

!pip install tensorflow==2.15.1

"""Checks to see what version is currently installed."""

import tensorflow as tf
print(tf.__version__)

!mkdir {HOME}/weights
!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt
!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt
!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt
!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt

!ls -la {HOME}/weights

SOURCE_IMAGE_PATH = "/content/unzip_test"

from google.colab import drive
drive.mount('/content/drive')

# Check if the data.yaml file exists
!ls /content/unzip_test/data.yaml
# Check if the weights file exists
!ls /content/yolov9-c-converted.pt
# Check if the config file exists
!ls /content/yolov9-c-converted.pt

# Check if the hyperparameter file exists
!ls /content/unzip_test/data.yaml

!pip install pathlib

!pip install albumentations

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import zipfile
import os

# Path to the zip file
zip_file_path = "/content/Social Distancing App  2.0.v2i.yolov9.zip"
# Directory where the unzipped files will be stored
unzip_dir = "/content/unzip_test"
# Create the directory if it doesn't exist
os.makedirs(unzip_dir, exist_ok=True)

# Unzipping the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(unzip_dir)

print(f"Files unzipped to {unzip_dir}")

import pathlib
import tensorflow as tf
from tensorflow import keras



dataset_url = "/content/unzip_test"
data_dir = tf.keras.utils.get_file('/content/Social Distancing App  2.0.v2i.yolov9.zip', origin=dataset_url, extract=True)
data_dir = pathlib.Path(data_dir).with_suffix('')

data_dir

#PosixPath just means that everything went through

!wget https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi.git

import torch

# Assuming 'state_dict' is your model's state dictionary
state_dict = model.state_dict()

# Specify the file path where you want to save the model
filepath = "/content/yolov9-e-converted.pt"

# Save the model state dictionary to the specified file
torch.save(state_dict, filepath)

# Commented out IPython magic to ensure Python compatibility.
# %cd yolov9

!ls models/

!find . -name "*.yaml"

import os
HOME = os.getcwd()
print(HOME)

import os
import cv2
import numpy as np
import albumentations as A
import matplotlib.pyplot as plt
from PIL import Image
import datetime
import tensorflow as tf
print("TensorFlow version:", tf.__version__)
from tensorflow.python.compiler.tensorrt import trt_convert as trt



#This trains the images and the import IPython.images display them in the runs/detect/exp3 folder in yolov9

#python -m torch.distributed.launch --nproc_per_node 4 --master_port 9527 train.py --workers 8 --device 0,1,2,3 --sync-bn --batch 128 --data /content/unzip_test/train/images --img 340 --cfg models/detect/gelan-c.yaml --weights '/content/yolov9-e-converted.pt' --name gelan-c --hyp hyp.scratch-high.yaml --min-items 0 --epochs 500 --close-mosaic 15
#!python train.py --weights /content/yolov9-t-converted.pt --data /content/yolov9/models/detect/yolo.yaml --img 640 --batch 16 --epochs 50 --device 0


!python train.py \
--batch 16 --epochs 30 --img 640 --device 0 --min-items 0 --close-mosaic 15 \
--data /content/unzip_test/data.yaml \
--weights /content/yolov9-t-converted.pt \
--cfg models/detect/gelan-c.yaml \
--hyp hyp.scratch-high.yaml

# Commented out IPython magic to ensure Python compatibility.
# Tensorboard  (optional)
# %load_ext tensorboard
# %tensorboard --logdir runs/train

from IPython.display import Image, display
Image_path = "/content/yolov9/runs/train/exp4/results.png"
display(Image(filename=Image_path, width=1000))

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

#Run Inference With Trained Weights
!python detect.py --weights /content/yolov9-t-converted.pt --conf 0.4 --source /content/unzip_test/test/images

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov9

!pip install pillow

"""Adding in Agumentations."""

from PIL import Image
import numpy as np
import albumentations as A
import cv2

import albumentations as A
transform = A.Compose([
    A.RandomCrop(width=256, height=256),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
])

import os
import cv2
import numpy as np
import albumentations as A
import matplotlib.pyplot as plt
from PIL import Image
import datetime
import tensorflow as tf

print("TensorFlow version:", tf.__version__)
from tensorflow.python.compiler.tensorrt import trt_convert as trt

# Define the transformation
def transformation():
    return A.Compose([
        A.HorizontalFlip(p=0.5),
        A.OneOf([
            A.CLAHE(p=1),
            A.HueSaturationValue(p=1)
        ], p=0.9)
    ])

# Load images from folder
def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        img = cv2.imread(img_path)
        if img is not None:
            images.append(img)
    return images

# Save images into new folders
def save_images(images, base_dir, metadata_file):
    counter = 1
    run_dir = os.path.join(base_dir, datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
    if not os.path.exists(run_dir):
        os.makedirs(run_dir)

    for image in images:
        filename = f'extract_{metadata_file}_{counter}.jpg'
        output_path = os.path.join(run_dir, filename)
        cv2.imwrite(output_path, image)
        counter += 1

    return run_dir

# Main function to apply transformations and save images
def process_images(images_folder, base_dir, metadata_file):
    images = load_images_from_folder(images_folder)
    print(f"Loaded {len(images)} images.")
    transform = transformation()

    transformed_images = []
    for image in images:
        transformed = transform(image=image)
        transformed_images.append(transformed['image'])

    new_folder = save_images(transformed_images, base_dir, metadata_file)
    print("Transformation and saving complete")
    return new_folder

# Directory paths
images_folder = "/content/yolov9/runs/detect/20240718-200015"
base_dir = "/content/yolov9/runs/detect"
metadata_file = "metadata_example"

# Process and save images
new_images_folder = process_images(images_folder, base_dir, metadata_file)

# Update data.yaml to point to the new folder
data_yaml_content = f"""
train: {new_images_folder}
val: /content/unzip_test/valid/images
test: /content/unzip_test/test

nc: 1
names: ['person']

roboflow:
  workspace: object-detection-quyvj
  project: social-distancing-app-2.0
  version: 2
  license: CC BY 4.0
  url: https://universe.roboflow.com/object-detection-quyvj/social-distancing-app-2.0/dataset/2
"""

with open('/content/yolov9/data.yaml', 'w') as f:
    f.write(data_yaml_content)

# Train the model using the new data.yaml
!python train.py \
--batch 16 --epochs 30 --img 640 --device 0 --min-items 0 --close-mosaic 15 \
--data /content/yolov9/data.yaml \
--weights /content/yolov9-t-converted.pt \
--cfg models/detect/gelan-c.yaml \
--hyp hyp.scratch-high.yaml

# Commented out IPython magic to ensure Python compatibility.
import tensorboard
# %load_ext tensorboard
# %tensorboard --logdir runs/train

!pip install comet_ml

from IPython.display import Image, display
Image_path = "/content/yolov9/runs/train/exp3/results.png"
display(Image(filename=Image_path, width=1000))

!python detect.py --weights /content/yolov9-t-converted.pt --conf 0.4 --source /content/augmented_data/20240719-152003/images

!ls /content/yolov9/models/detect

!pip install roboflow
import roboflow
roboflow.login()

"""This is importing object detection n

```
# This is formatted as code
```


"""

import roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="Xy9TSDYjSvrRt3AWLG80")
project = rf.workspace("object-detection-quyvj").project("car_object_detection2")
version = project.version(3)
dataset = version.download("yolov9")

# Train the model using the new data.yaml
!python train.py \
--batch 16 --epochs 30 --img 640 --device 0 --min-items 0 --close-mosaic 15 \
--data /content/yolov9/Car_Object_detection2-3/data.yaml \
--weights /content/yolov9-t-converted.pt \
--cfg models/detect/gelan-c.yaml \
--hyp hyp.scratch-high.yaml

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# Tensorboard  (optional)
# %reload_ext tensorflow
# %tensorboard --logdir runs/train
tensorboard --logdir==logs/fit

from IPython.display import Image, display
Image_path = "/content/yolov9/runs/train/exp3/results.png"
display(Image(filename=Image_path, width=1000))

import tensorboard
tensorboard()

# Commented out IPython magic to ensure Python compatibility.
import tensorboard
# %load_ext tensorboard
# %tensorboard --logdir runs/train

import os
import shutil

# Create a new directory for the combined dataset
combined_data_path = '/content/combined_datasets2'
os.makedirs(combined_data_path, exist_ok=True)
os.makedirs(os.path.join(combined_data_path, 'images'), exist_ok=True)
os.makedirs(os.path.join(combined_data_path, 'labels'), exist_ok=True)

# Function to move files from source to destination
def move_files(src_folder, dst_folder):
    if not os.path.exists(src_folder):
        print(f"Source folder does not exist: {src_folder}")
        return
    for file_name in os.listdir(src_folder):
        full_file_name = os.path.join(src_folder, file_name)
        if os.path.isfile(full_file_name):
            shutil.move(full_file_name, dst_folder)

# List of datasets and their paths
datasets = [
    '/content/unzip_test/train',
    '/content/unzip_test/val',
    '/content/unzip_test/test',
    '/content/augmented_data/20240723-171715/train',
    '/content/augmented_data/20240723-171715/val',
    '/content/augmented_data/20240723-171715/test'
]

data_yaml_content = f"""
# data.yaml
train: /content/combined_datasets/train/images
val: /content/combined_datasets/valid/images
test: /content/combined_datasets/test/images

nc: 2
names: ['cars', 'person',]  # class names

"""


# Move images and labels from all datasets to the combined directory
for dataset in datasets:
    image_path = os.path.join(dataset, 'images')
    label_path = os.path.join(dataset, 'labels')
    if os.path.exists(image_path):
        move_files(image_path, os.path.join(combined_data_path, 'images'))
    else:
        print(f"Images path does not exist: {image_path}")
    if os.path.exists(label_path):
        move_files(label_path, os.path.join(combined_data_path, 'labels'))
    else:
        print(f"Labels path does not exist: {label_path}")

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="Xy9TSDYjSvrRt3AWLG80")
project = rf.workspace("object-detection-quyvj").project("person_-car")
version = project.version(1)
dataset = version.download("yolov9")

!python train.py \
--batch 16 --epochs 30 --img 640 --device 0 --min-items 0 --close-mosaic 15 \
--data /content/Person_-Car-1/data.yaml \
--weights /content/yolov9-t-converted.pt \
--cfg models/detect/gelan-c.yaml \
--hyp hyp.scratch-high.yaml

# Commented out IPython magic to ensure Python compatibility.
import tensorboard
# %load_ext tensorboard
# %tensorboard --logdir runs/train

!python detect.py --weights /content/yolov9-t-converted.pt --conf 0.4 --source /content/Person_-Car-1/test/images